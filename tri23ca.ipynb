{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00c67f2-d34d-457c-a3b4-1e7c7cd24914",
   "metadata": {},
   "source": [
    "# How to be Choosy: Toxic Release Inventory 2023 - CA\n",
    "_by Michelle Hoda Wilkerson_\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CalCoRE/choosy/main?urlpath=%2Fdoc%2Ftree%2Ftri23ca.ipynb) <- Click here to open an interactive version of this notebook!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> This notebook is written to illustrate the data wrangling moves described in [anonymized manuscript], using a dataset about toxic release events in California as reported by the U. S. Environmental Protection Agency in the 2023 (see <a href=\"#about\">here</a> for more information). Some of the text below is excerpted from the manuscript. Each section below corresponds to a subheading in the manuscript. See also How to be Choosy: Billboard Hot 100. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c04d9-3172-4c1f-8f66-5943fde61862",
   "metadata": {},
   "source": [
    "This is a Jupyter Python notebook. It mixes together Python code and text into one runnable, editable document (like a Word file or Google Doc). When you see code, you can run it by clicking the \"Play\" button in your interface. You can also edit it and see what happens! Often, pieces of code that appear later in the document rely on piece of code that appear earlier. So if you are a beginner, it's useful to work through every chunk of the document in order, top to bottom, before hopping around or making too many edits.\n",
    "\n",
    "With any Jupyter notebook, we begin by importing the necessary libraries. You should run the cell below before running any other code. Here, we are using the `pandas` library, an industry standard that provides us with special methods for reading in and working with data in Python. We also import `folium`, which allows us to create maps using latitude and longitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49358233-5bb1-4f0a-a277-f06355ffa1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas # for data wrangling\n",
    "import folium # for the map\n",
    "import numpy as np # for calculations\n",
    "import warnings # to silence warnings\n",
    "\n",
    "# if there are more than 10 records to show in a table, only show the first and last 5\n",
    "pandas.set_option('display.max_rows', 10) \n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a900f-00bc-4c4e-b224-2ad2d80a1f82",
   "metadata": {},
   "source": [
    "# Introduction to TRI23CA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1b602-4394-4423-b7ed-5771a903e29e",
   "metadata": {},
   "source": [
    "Let's check out the dataset. In the setup code above, we loaded the `pandas` library and other libraries to help us process this data. In the code below, we read the csv file and use `pandas` to turn it into a data frame called `tri23ca`. The next line of code, which just says `tri23ca`, will give a brief summary of the contents of the dataframe so you can check and make sure it has been read and processed correctly. Since there are too many cases to list, you will see the first five rows and the last five rows of the dataset, with \"...\" in the middle to indicate there are more cases that are not shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efcc6a-b779-43a7-9561-69fb86c4dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the contents of tri23ca.csv into a dataframe\n",
    "tri23ca = pandas.read_csv(\"tri23ca.csv\")\n",
    "\n",
    "tri23ca # show us the contents of the new data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da1cc7c-544a-457a-8453-dc9751b31f33",
   "metadata": {},
   "source": [
    "At the bottom of the output from our code above, we can see the specific dimensions of this dataset. It has 3482 cases (rows), and 122 attributes (columns). Below, we model the different wrangling strategies described in _How to be Choosy_ to reduce the size and/or complexity of the `tri23ca` dataset so that it is more appropriate for different educational applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd643f9-403a-4e43-9fbd-9637d35c48f2",
   "metadata": {},
   "source": [
    "Let's create a map of all the toxic release events recorded in the tri23ca dataset, using the listed latitude and longitude of each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632f335-61f6-4f05-a397-20515bc33d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the center of the map\n",
    "center_lat = tri23ca['Latitude'].mean()\n",
    "center_lon = tri23ca['Longitude'].mean()\n",
    "\n",
    "# Create the Folium map\n",
    "map = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n",
    "\n",
    "# Add markers for each row in the DataFrame\n",
    "for index, row in tri23ca.iterrows():\n",
    "    lat = row['Latitude']\n",
    "    lon = row['Longitude']\n",
    "\n",
    "    # Add the marker\n",
    "    folium.Marker([lat, lon]).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ccd7d5-95b5-4aa0-821c-7ec2b9e0ecc6",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Wrangling Too Many Cases](#Wrangling-Too-Many-Cases-)\n",
    "    * [Random Selection](#Random-Selection-)\n",
    "    * [Purposeful Selection by Attribute(s)](#Purposeful-Selection-by-Attribute(s)-)\n",
    "    * [Building Your Own Selection Attribute](#Building-Your-Own-Selection-Attribute-)\n",
    "* [Wrangling Too Many Attributes](#Wrangling-Too-Many-Attributes-)\n",
    "    * [Thematic Selection](#Thematic-Selection-)\n",
    "    * [Pattern-Driven Selection](#Pattern-Driven-Selection-)\n",
    "    * [Question-Driven Selection](#Question-Driven-Selection-)\n",
    "* [More About This Dataset](#About-the-Toxic-Release-Inventory-2023---CA-Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0125b-0617-4689-bdd0-0ec688f36329",
   "metadata": {},
   "source": [
    "# Wrangling Too Many Cases <a class=\"anchor\" id=\"cases\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2b639-da2c-421b-bb81-c4efae1b0b48",
   "metadata": {},
   "source": [
    "## Random Selection <a class=\"anchor\" id=\"random\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fb4ff-fb21-41d5-8cc8-6c1261d76a5e",
   "metadata": {},
   "source": [
    "Random selection extracts random rows from a large dataset to create one of a more manageable size. This is the most appropriate strategy for downsizing a dataset while preserving a representative snapshot of the full phenomenon to be studied. Starting with your dataframe, you can create a random selection from that dataframe using the sample() method. Below, we select exactly 100 random cases from the `tri23ca` dataset and save them as a new reduced dataset called minitri23ca. If you run the code more than once, you will see that different cases are included in the dataset output each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144f4c28-29f2-40d7-bd2e-a4a7475f4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "minitri23ca = tri23ca.sample(100) # put a randomly selected 5000 rows in bh100reduced\n",
    "minitri23ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb755a90-d28a-4e33-9864-0f222acc504a",
   "metadata": {},
   "source": [
    "A related technique is interpolated selection, or selecting every <i>n</i>th row of a data table. This might be useful when the order of the data matters (for example, if records are organized by date and you are interested in modeling patterns over time). However, we do not recommend interpolated selection unless you have a specific reason for using this method, because it can also lead to unintentionally non-random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319f9eb-476e-4098-ac02-72d280606c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minitri23ca = tri23ca.iloc[::30, :] # put every 30th row of tri23ca in minitri23ca\n",
    "minitri23ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3913c9-7e33-4a80-83a7-191e219b58c9",
   "metadata": {},
   "source": [
    "## Purposeful Selection by Attribute(s) <a class=\"anchor\" id=\"purposeful\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9750466-95e8-4e79-b0b8-8524382a32c6",
   "metadata": {},
   "source": [
    "Purposeful selection involves reducing a dataset so that it only includes records with certain characteristics related to one or more attributes. This method is appropriate if you suspect that the majority of records in your too-large dataset are not useful or usable for your intended activity. To get all the cases in a dataframe that meet certain conditions, use the expression dataframe[condition]. Below, we want only the toxic releases that involved known carcinogens, represented in tri23ca by records where the ‘Carcinogen’ value is set to YES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9aed3-8d52-4593-9571-e9441af1115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "carcinogens = tri23ca['Carcinogen']==\"YES\"  # for each song, see if the highest position was 1\n",
    "minitri23ca = tri23ca[carcinogens]              # put only top song records in the reduced dataset\n",
    "minitri23ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b85b67-bdac-41c6-84fd-32359cb8efd4",
   "metadata": {},
   "source": [
    "## Building Your Own Selection Attribute <a class=\"anchor\" id=\"byo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2626c0e-4f3f-473a-b4fa-3695d6e46a99",
   "metadata": {},
   "source": [
    "There are other ways of creating a smaller dataset based on information that is not already available in the dataset itself. These could be specific cases that you identify manually, or cases you might identify using computer code to extract some new, meaningful information from the attributes you already have. These techniques allow teachers and students the most customization, but they require careful planning to select and identify which cases should be included and to consider how those decisions will shape what analyses and claims are appropriate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbab21e-0482-47d6-90c9-e08d8f2b4ab6",
   "metadata": {},
   "source": [
    "### By Identifying Specific Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320eb178-8bbf-4f25-9504-b0d6b22f0a53",
   "metadata": {},
   "source": [
    "Sometimes, you may want to create a small dataset through manually selecting a small number of cases from a larger data corpus. This can be helpful, for example, if you would like students to work with a small set of familiar cases before diving into larger-scale analyses. The Billboard Hot 100 notebook shows an example of how you might build a list of the ID numbers or _indices_ of the cases you want to include. Below, we create a dataset by directly searching for certain words, in order to create a dataset that includes records from facilities that are directly mentioned in the fifth paragraph of [this 2023 CalMatters article](https://calmatters.org/environment/2023/12/california-hazardous-toxic-waste-mexico/). These facilities are presented as examples of some of the many California-based facilities that export their waste to recycling facilities in Mexico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed92dd0-dcdc-4bdd-9264-f0771984ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the lines below to create a list of all the records with Facility names\n",
    "# the plus sign attaches lists of records for each keyword together into one list\n",
    "\n",
    "mentionedFacilities =  tri23ca['Facility name'].str.contains(\"SHERWIN\") + tri23ca['Facility name'].str.contains(\"NAVY\") + tri23ca['Facility name'].str.contains(\"TESLA\")\n",
    "minitri23ca = tri23ca[mentionedFacilities]\n",
    "minitri23ca # show the full records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b2bd0-b18d-4e9c-a6a3-c2a02d34fdad",
   "metadata": {},
   "source": [
    "### Using Code to Construct a New Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3bbf9-0636-4a59-80fc-65b8d7d094f2",
   "metadata": {},
   "source": [
    "In other cases, you may want to use code to systematically filter certain records for deeper analysis. Let's imagine we want to explore records where carcinogenic chemicals that are listed as hazardous under the Clean Air Act were released on-site at facilities, either as \"Fugitive air\" or \"Stack air\" releases. This requires a complex combination of conditions, which we step through one by one below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea21c45-c636-446c-94f2-9c140b6ed462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we can get all the records that released a Clean Air Act hazardous chemical.\n",
    "searchFor = tri23ca['Clean air act chemical']==\"YES\" \n",
    "minitri23ca = tri23ca[searchFor]\n",
    "# this yields 2123 records\n",
    "\n",
    "# from those records that we know involve Clean Air Act chemicals, find the carcinogens.\n",
    "searchFor = minitri23ca['Carcinogen']==\"YES\"\n",
    "minitri23ca = minitri23ca[searchFor]\n",
    "# this yields 729 records\n",
    "\n",
    "# finally, let's select records where there was an air release. We'll keep the record in \n",
    "# the dataset if the amount of chemicals released as 'Fugitive air' or as 'Stack air'\n",
    "# are larger than 0.\n",
    "minitri23ca = minitri23ca[(minitri23ca['Fugitive air']>0) | (minitri23ca['Stack air']>0)]\n",
    "minitri23ca # finally, there are a total of 554 records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c60265-c3da-4a75-a5af-42e6f6d941a9",
   "metadata": {},
   "source": [
    "# Wrangling Too Many Attributes <a class=\"anchor\" id=\"attributes\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74362c0d-1d29-413b-840e-085d83097540",
   "metadata": {},
   "source": [
    "Another common issue when using large public datasets for educational purposes is the problem of too many attributes. Environmental datasets such as the TRI22CA dataset we use here can include hundreds of specific indicators; survey datasets from organizations such as the Pew Research Center similarly report scores of questions per participant. While having access to so many attributes can enable the pursuit of a variety of investigative questions, it can easily become overwhelming. Working with these datasets requires planning and thoughtfulness to consider which attributes are actually connected to one's research question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10588bb7-ce20-4139-8fa3-8a5aa1b60023",
   "metadata": {},
   "source": [
    "## Thematic Selection <a class=\"anchor\" id=\"thematic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addf00d8-7035-4d39-a03b-be3da11b68b8",
   "metadata": {},
   "source": [
    "Thematic selection involves splitting a dataset up into related, but distinct, groups of attributes that are more likely to be conceptually or statistically related to one another. Thematic attribute selection can be especially useful for jigsaw-like activities, in which different groups explore different aspects of an interconnected system. Below, we create thematic groups by information type in each toxic release report. You can then access a dataset with a reduced number of selected attributes by calling the dataframe with the attribute group name in brackets. You can include attributes from multiple groups using the plus sign: `dataframe[selection1+selection2]`. Below, we create a dataset with only the facility information and basic release information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e8431-a848-4509-aaaa-204700cf4b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our thematic categories using lists of column names\n",
    "facility = ['Facility name','Federal facility']\n",
    "location = ['Street address','City','County','St','Zip','Bia','Tribe','Latitude','Longitude','Horizontal datum']\n",
    "company = ['Parent co name','Parent co db name','Standard parent co name','Foriegn parent co name','Foriegn parent co db num','Standard foriegn parent co name']\n",
    "facilityType = ['Industry sector code','Industry sector','Primary sic','Sic 2','Sic 3','Sic 4','Sic 5','Sic 6','Primary naics','Naics 2','Naics 3','Naics 4','Naics 5','Naics 6']\n",
    "filingInfo = ['Doc_ctrl_num','Form type']\n",
    "basicInfo = ['Chemical','Elemental metal included','Clean air act chemical','Classification','Metal','Metal category','Carcinogen','PBT','PFAS','Unit of measure']\n",
    "chemicalInfo = ['Tri chemical/compound id','Cas#','Srs id']\n",
    "onSite = ['Fugitive air','Stack air','Water','Underground','Underground cl i','Underground cl ii-v','RCRA C landfill','Other landfills','Land treatment','RCRA Surface im','Other surface im','Other disposal','On-site total']\n",
    "transfers = ['POTW Transfers for release','POTW Transfers for treatment','POTW Total transfers','Unclassified','Total transfer']\n",
    "offSiteRelease = ['M10','M41','M62','M40 metal','M61 metal','M71','M81','M82','M72','M63','M66','M67','M64','M65','M73','M79','M90','M94','M99','Off-site release total']\n",
    "offSiteRecycling = ['M20','M24','M26','M28','M93','Off-site recycled total']\n",
    "offSiteRecovery = ['M56','M92','Off-site energy recovery t']\n",
    "offSiteTreated = ['M40 non-metal','M50','M54','M61 non-metal','M69','M95','Off-site treated total']\n",
    "toxicReleases = ['Total releases','Releases','On-site contained','Off-site other','Off-site contain','Off-site other r','Energy recover on','Energy recover of','Recycling on site','Recycling off sit','Treatment on site','Treatment off site','Production waste','One-time release','Prod_ratio_or_activity','Production ratio']\n",
    "\n",
    "# use brackets to reference only the columns associated with one category.\n",
    "minitri23ca = tri23ca[facility+basicInfo]\n",
    "minitri23ca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f624a1-84c6-4fc1-aaa3-c4abbda5c207",
   "metadata": {},
   "source": [
    "## Pattern-Driven Selection <a class=\"anchor\" id=\"pattern\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3336d-deaa-4645-9194-c829a1ad1e0e",
   "metadata": {},
   "source": [
    "Similar to thematic selection, pattern-driven selection allows educators and students to focus only on the attributes that are known to align with investigative or pedagogical goals. Whereas thematic selection focuses on the real-world relationships and system components that a student may wish to explore, pattern selection focuses attention on particular mathematical relationships and analytic methods that the dataset makes available for investigation.\n",
    "\n",
    "Below, we demonstrate one example of pattern-driven selection that focuses on attribute type. We create a group focused on boolean variables about each toxic release event. Using this form of pattern-driven selection, educators and designers can introduce students to the methods and strategies for exploring categorical relationships in a dataset, and to identify the ones that might be especially worth pursuing further. We use Python to create crosstabs for a set of relevant columns in the dataframe. In BH100, we demonstrate how to similarly generate a correlation matrix to examine the patterns among quantitative columns in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38263846-34a4-49ab-94ad-ad9f0059b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's limit our dataset to some of the most relevant categorical attributes\n",
    "toExplore = ['Federal facility',\n",
    "             'Clean air act chemical',\n",
    "             'Carcinogen',\n",
    "             'PBT']\n",
    "minitri23ca = tri23ca[toExplore]\n",
    "\n",
    "# Create a dictionary to store crosstab matrices\n",
    "crosstab_matrices = {}\n",
    "\n",
    "# Generate crosstab matrices for each pair of columns\n",
    "for col1 in toExplore:\n",
    "    for col2 in toExplore:\n",
    "        if col1 < col2:  # Just look pairwise at each column once\n",
    "            crosstab_matrices[(col1, col2)] = pandas.crosstab(minitri23ca[col1], minitri23ca[col2], normalize='all').round(2)\n",
    "\n",
    "# Print the crosstab matrices\n",
    "for (col1, col2), matrix in crosstab_matrices.items():\n",
    "    print(f\"Crosstab: {col1} vs {col2}\")\n",
    "    print(matrix)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03c107-b43a-4496-aae5-cf56f8913b19",
   "metadata": {},
   "source": [
    "## Question-Driven Selection <a class=\"anchor\" id=\"question\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515413ee-1d92-4bb2-9f70-e45f4eeb10ae",
   "metadata": {},
   "source": [
    "Question-driven selection involves identifying the attributes within a dataset that are most appropriate for addressing a particular question–whether that question is posed by a student, or posed as a driving question within curriculum materials themselves. We suggest making 3-5 attributes available for a given question in these curricular configurations. When students are constructing their own questions, we recommend encouraging them to also brainstorm what kind of data they would need to address their questions _before_ they have access to a dataset. Once they are provided with access, we suggest asking students to make predictions and construct hypotheses about what patterns they might find. \n",
    "\n",
    "Below, we assemble data to address the simple descriptive question, \"What industries most frequently reported toxic release events in California in 2023?\" We then dig deeper, supplementing the dataset to address a second question of whether those more frequently reporting industries are more likely than others to release carcinogens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b978f8-d23c-47ed-945d-afde31eeacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploreFreq = ['Facility name',\n",
    "              'Industry sector'] \n",
    "\n",
    "minitri23ca = tri23ca[exploreFreq]\n",
    "\n",
    "#count the number of records for each Industry sector category\n",
    "industryCount = minitri23ca['Industry sector'].value_counts()\n",
    "totalCount = sum(industryCount)\n",
    "\n",
    "#show the record counts\n",
    "print(industryCount)\n",
    "\n",
    "#show the record counts as percent of total reports\n",
    "industryCount/totalCount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5fd25-7628-49ba-a999-82877cf54413",
   "metadata": {},
   "source": [
    "We see that the two Industry sectors that most frequently report toxic release events are  \"Chemicals\" and \"Petroleum.\" Together, these two sectors account for over one third of the toxic release reports in the dataset. We may wish to dig deeper, wondering whether these industries report releases of carcinogens more frequently than others. Let's see what proportion of top industries, versus other industries, report the release of carcinogenic chemicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87565edb-1075-4b9c-83c0-7909cc3f0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's add the carcinogen attribute to the dataset\n",
    "minitri23ca = tri23ca[ exploreFreq + ['Carcinogen'] ]\n",
    "\n",
    "#and, let's group industries by \"top\" and \"other\"\n",
    "conditions = [minitri23ca['Industry sector'].isin(['Chemicals', 'Petroleum'])]\n",
    "choices = [\"YES\"]\n",
    "minitri23ca['Top Industry?'] = np.select(conditions, choices, default=\"NO\")\n",
    "\n",
    "#recode the 'Carcinogen' attribute with YES = 1 and NO = 0\n",
    "conditions = [minitri23ca['Carcinogen'] == \"YES\"]\n",
    "choices = [1]\n",
    "minitri23ca['Carcinogen'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "#calculate difference in means between top and other industries\n",
    "sum_by_category = minitri23ca.groupby('Top Industry?')['Carcinogen'].mean()\n",
    "sum_by_category['YES'] - sum_by_category['NO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f02e7b-0c9b-490f-a575-0edffb234cd0",
   "metadata": {},
   "source": [
    "This follow-up industry sector question motivates hypothesis generation. We can consider how our commonsense question translates into more formal hypotheses. The _null_ hypothesis is that the proportion of carcinogenic releases reported by top industries will be the same as the proportion of carcinogenic releases reported by other industries. While we can see above that the proportion is different--top industries report the release of carcinogenic toxins at a higher rate (32%) than other industries (25%), we need to check and see whether this difference in proportion is more likely due to existing variation in the dataset in general, rather than due to systematic differences between industry groups. \n",
    "\n",
    "We can create a simulation that generates what these data would look like if the industry category wasn't related to the likelihood of a reported carcinogenic release. We simulate this null hypothesis by randomly assigning different industries to each toxic release event, and recording the resulting difference in proportions of carcinogenic releases across those (randomly assigned) groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc802da6-5651-4526-a943-3a875253685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all the Top Industry? values and shuffle them around\n",
    "shuffle = minitri23ca.sample(frac=1,replace=False)['Top Industry?'].values\n",
    "\n",
    "# add the shuffled values as a new column\n",
    "minitri23ca['Shuffled Industry'] = shuffle\n",
    "\n",
    "# see the proportion of carcinogenic events if they were assigned \n",
    "# to the new random, shuffled categories\n",
    "sum_by_category = minitri23ca.groupby('Shuffled Industry')['Carcinogen'].mean()\n",
    "abs(sum_by_category['YES'] - sum_by_category['NO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1fed4-7db1-45b4-8a6e-87243e6268db",
   "metadata": {},
   "source": [
    "If we run the simulation many times, we get a distribution of means that we would expect from many, many instances of the null hypothesis in a probabilistic world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24dd4f8-bb71-4028-8b84-22e1729ea842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function runIt to repeat the simulation process above\n",
    "def runIt():\n",
    "    shuffle = minitri23ca.sample(frac=1,replace=False)['Top Industry?'].values\n",
    "    minitri23ca['Shuffled Industry'] = shuffle\n",
    "    sum_by_category = minitri23ca.groupby('Shuffled Industry')['Carcinogen'].mean()\n",
    "    return abs(sum_by_category['YES'] - sum_by_category['NO'])\n",
    "\n",
    "distances = []\n",
    "\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    new_distance = runIt()\n",
    "    distances = np.append(distances, new_distance)\n",
    "\n",
    "sum_by_category = minitri23ca.groupby('Top Industry?')['Carcinogen'].mean()\n",
    "observed = abs(sum_by_category['YES'] - sum_by_category['NO'])\n",
    "\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ad3aa-f39f-47cf-a545-75e68fe9da88",
   "metadata": {},
   "source": [
    "After repeating this test 10000 times, we can see what the distribution of differences in proportions between the two top reporting industries (\"Chemical\" and \"Petroleum\") and compare the simulated distributions of the null hypothesis to our observed distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154198a1-4fc0-49ad-8dd3-2242ffe942cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(distances, bins=10)\n",
    "plt.axvline(x=observed, color='magenta', label='Observed difference')\n",
    "\n",
    "empirical_p = np.count_nonzero(distances >= observed) / repetitions\n",
    "empirical_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d24c5-0f28-43f3-af23-169697a17607",
   "metadata": {},
   "source": [
    "The purple line that represents the actual observed difference in proportions of carcinogenic releases by top reporters in the TRI23CA dataset versus other reporters is likely to appear even when there is no difference between the groups (in the simulation, the groups are randomly assigned to events). This is confirmed in our calculation of a rather large empirical p-value. This means we cannot reject the null hypothesis, that there is not a difference between the proportion of carcinogenic chemical releases reported by top industries versus other industries. We invite the ambitious reader, as an exercise, to revise the code above to examine the relationship between only the Petroleum industry and the release of carcinogenic chemicals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b2484-59a2-4edc-94af-53bda3c0c98e",
   "metadata": {},
   "source": [
    "# About the Toxic Release Inventory 2023 - CA Dataset \n",
    "\n",
    "This dataset includes all toxic release inventory reports recorded by the U. S. Environmental Protection Agency for facilitites in the State of California for the year 2023.\n",
    "\n",
    "### About the Attribute Groups\n",
    "Each record includes information about the reporting Facility (by federal identifiers), the Location of the release event (address, city, county, etc.), the Company responsible for the event, the Facility Type (e.g. industry categories) and Filing details (e.g. document tracking number and form submitted). Each toxic release record also includes Basic Information about the released chemicals and their risk factors, as well as more detailed Chemical Information, and there are several attribute groups with detailed reporting information depending on the type of release (e.g. whether the toxin was released on site, transferred elsewhere, recycled, treated, etc.).\n",
    "\n",
    "### About the Attributes\n",
    "Information about all 122 attributes can be found in the EPA's [Guide to the TRI Basic Data Files](https://www.epa.gov/system/files/documents/2024-08/basic_data_files_documentation_august_2024.pdf). They can also be reviewed by revieweing the metainformation available in the CODAP document [here](https://codap.concord.org/app/static/dg/en/cert/index.html#shared=https%3A%2F%2Fcfm-shared.concord.org%2FPvQBqkl1RCqPETiMddga%2Ffile.json). The attributes that are most frequently referenced in the Choosy paper include:\n",
    "- *Facility Name* of the reporter.\n",
    "- *City* in which the reporting facility is located.\n",
    "- *Industry Sector* is a categorization of primary industry or sector the reporting facility belongs to.\n",
    "- *Clean Air Act Chemical* is a boolean flag indicating whether the released chemical is listed as a hazardous air pollutant under the Clean Air Act.\n",
    "- *Carcinogen* indicates whether the released chemical is identified as a carcinogen by the Occupational Health and Safety Administration.\n",
    "- *PBT* indicates whether a chemical is identified as a persistent, bioaccumulative,\n",
    "toxic (PBT) chemical.\n",
    "- *PFAS* indicates whether a chemical is identified as a per- and polyfluoroalkyl substance (PFAS).\n",
    "\n",
    "### History and Purpose\n",
    "An earlier version of this dataset was initially imported into CODAP in Summer 2024 for consideration as part of the curricular materials developed for the Writing Data Stories project (DGE-2430522). It was updated in March 2025, to accompany \"How to be Choosy,\" a manuscript submission about wrangling educational datasets to make them more managable and meaningful for classroom use.\n",
    "\n",
    "### Data Sources and Data Cleaning\n",
    "This dataset was downloaded on March 5, 2025 from the U. S. Environmental Protection Agency's [Toxic Release Inventory Basic Data Tool](https://www.epa.gov/toxics-release-inventory-tri-program/tri-basic-data-files-calendar-years-1987-present), and filtered to only show data for the state of California. Attributes were renamed for usability using the EPA's [Guide to the TRI Basic Data Files](https://www.epa.gov/system/files/documents/2024-08/basic_data_files_documentation_august_2024.pdf). Michelle Wilkerson of the WDS team  imported attribute titles and descriptions from the original dataset, editing a few descriptions for readability at the middle school level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3b1bb-a104-4d63-a7f5-f6bb5a41307b",
   "metadata": {},
   "source": [
    "The development of these materials was supported by the National Science Foundation under Grant No. IIS-1900606."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
